---
title: "Midterm STT 5811"
author: "Huy Tu"
date: '`r Sys.Date()`'
output: html_document
---

```{r, label = "SETUP", echo = FALSE, results= 'hide', message = FALSE, warning = FALSE}
library(knitr)
library(stringi)
knitr::opts_chunk$set(comment = NA, fig.show = 'as.is', fig.height = 4, fig.width = 4, prompt = TRUE, highlight = TRUE, tidy = FALSE, warning = FALSE, message = FALSE, tidy.opts=list(blank = TRUE, width.cutoff= 75, cache = TRUE))
GA <- read.csv("GA.csv", colClasses = "character")
```


**Midterm Directions:**  Answer all questions to the midterm with complete sentences.  Make sure to show all code and use inline code when reporting numerical answers to questions.  The Gettysburg address is stored in the `Data` folder of the class repository as `GA.csv`.  Please italicize all answers. Create a directory under your private GitHub repository named `MidTerm`.  Move this document (`MidTerm5811.Rmd`) to your `MidTerm` directory as well as the `GA.csv` file.  Push your completed work to your private repository no later than 17:00 October 9, 2015.   


(a)  Read the Gettysburg address into an object named `GA` using the `read.csv` function (use `colClasses = "character"`).  Convert all words used in the Gettysburg address to lower case using the function `tolower`.  Show the first six words in the object `GA`. [2 pts]  

```{r}
a <- read.csv('GA.csv', colClasses = "character")
a$words <- tolower(c(a$words))
for (i in 1:6 ) {
  print(a$words[i])
}

```

(b) Set the seed value to 649 (`set.seed(649)`).  Use the function `sample` to take a simple random sample of size 10 from the Gettysburg address and store the results in the object `SAMPLE10`.  Show the results of `SAMPLE10`. [2 pts]

```{r}
set.seed(649)
n = 10
SAMPLE10 <- sample(a$words, size=n, replace = FALSE)
SAMPLE10
```

(c) Consider the following variables and identify each as quantitative or categorical: [2 pts]
* length of word (number of letters) - Type: *quantitative*
* whether or not word contains the letter `e` - Type: *categorical*

(d) Use the package `stringi` and write `R` code to determine the string length of each word in `SAMPLE10`. Create a logical vector indicating whether each word in `SAMPLE10` contains one or more `e`s. Use `R` code to count the number of words containing one or more `e`s in `SAMPLE10`. [4 pts]

```{r}
STR_L <- stri_length(SAMPLE10)
STR_L
```

```{r}
STR_E <- stri_count_fixed(SAMPLE10, 'e')>=1
STR_E <- sum(STR_E)
STR_E
```

* *The number of words containing one or more `e`s in `SAMPLE10` is `r STR_E`.*

(e) What is the average word length for `SAMPLE10`?  [2 pts]

```{r}
AVG_W_L <- mean(STR_L)
AVG_W_L
```

* *The average word length for `SAMPLE10` is `r AVG_W_L`.*


(f) Is the average length you calculated in e. a parameter or a statistic? Explain. Do we know its value? What symbol can we use to denote its value? [3 pts]

* *The calculated result in e of the average word length is a statistic because the value comes from a simple random sample and not the entire population.*

* *Yes, we know its value which is 3.8*

* *The symbol we can use to denote its value is $\bar{x}$.*

(g) The average length of all 268 words in this population is `r mean(stringi::stri_length(GA$words))` letters. Is this number a parameter or a statistic?  Do we know its value? What symbol can we use to denote its value? [3 pts]

```{r}
P_Mean <- mean(stringi::stri_length(GA$words))
P_Mean
```

* *This number would be a parameter because it is the value indicating the mean of the whole entire population.*

* *Yes, we know its value which is `r P_Mean`*

* *The symbol use to denote its value is $\mu$.*

(h) Simulate $m = 150$ students each taking a simple random sample (of size $n = 10$) of the words in the Gettysburg address.  Use a seed of 55.  Store the length of each word in an `R` object (Hint: use a matrix).  Construct a dotplot displaying the average word length of the SRS for each of the the $m = 150$ students. [12 pts]

*This simulation pretends there are $m=150$ students.*

```{r}
set.seed(55)

m = 150
n = 10

A = matrix(NA, ncol = n, nrow = m)

for (i in 1:m) {
  SAMPLE_M <- sample(a$words, size=10, replace = FALSE)
  A[i,] = stri_length(SAMPLE_M)
}
DF <- data.frame(AVG_LEN = apply(A, 1, mean))
head(DF)

library(ggplot2)
ggplot(data = DF, aes(x = AVG_LEN)) + 
  geom_dotplot(binwidth = .15, color = "yellow") + 
  labs(title = "Avg Word Length", x = "Avg Word Length", y = " ") + theme_bw()

```


(i)  Characterize the distribution of these sample means. [3 pts]

```{r}
summary(DF$AVG_LEN)
Five_SUM <- fivenum(DF$AVG_LEN)
S_MED <-median(DF$AVG_LEN, na.rm = TRUE)
S_MED
IQRspread <-IQR(DF$AVG_LEN, na.rm = TRUE)
IQRspread
```

* *The distribution is unimodal and skewed right with a median of `r Five_SUM[3]`, minimum of `r Five_SUM[1]`, maximum of `r Five_SUM[5]`, and spread of `r IQRspread`.*

(j) Write `R` code that determines how many and what proportion of the $m = 150$ simulated students had a sample mean word length that exceeded the population mean word length? [2 pts]

```{r}

population_mean <- mean(DF$AVG_LEN)
population_mean
count = 0
for (i in 1:(m)) {
  if(DF$AVG_LEN[i] > population_mean)
  {
    count = count + 1
  }
}
count 
prop <- count/m
prop 
```

* *In $m = 150$ simulated students there are `r count` students had a sample mean word length that exceeded the population mean word length which is `r prop` as the proportion.*

(k)  Write `R` code that simulates $m = 10000$ students each taking a simple random sample of size $n = 81$ words from the Gettysburg address using a seed of 34.  Create a data frame `DF` with a variable `AvgLen` that contains the average word length for each of the $m = 10000$ simple random samples.  Show the first eight values of `AvgLen`.  [10 pts] 

```{r}
set.seed(34)

m = 10000
n = 81
k = 8

A = matrix(NA, ncol = n, nrow = m)

for (i in 1:m) {
  SAMPLE_M <- sample(a$words, size=n, replace = FALSE)
  A[i,] = stri_length(SAMPLE_M)
}

DF <- data.frame(AvgLen = apply(A, 1, mean))
head(DF)

for (j in 1:k) {
  print(DF$AvgLen[j])
}

```


(l) Compute the population mean ($\mu_{\bar{x}}$) and population standard deviation for average word length ($\sigma_{\bar{x}}$) of the Gettysburg address storing the results in the objects `EW` and `SWA`, respectively.  Make sure to use a finite population correction factor, $(N - n)/(N - 1)$, when computing $\sigma_{\bar{x}}$.  Store the value for $\sigma_{\bar{x}}$ without a finite population correction factor in `SW`.  Compute the mean and standard deviation of the values in `AvgLen`. [12 pts]  

```{r}
N<-length(a$words)
n<-81
EW<-mean(stringi::stri_length(a$words))     #population mean
EW
T_WL <-table(stri_length(a$words))
T_WL
T_Vectors <-as.numeric(names(T_WL)) 
T_Prop <-T_WL/N                             # Theoretical Probability
FPC<-(N-n)/(N-1)                            # Finite correction
SWA<-sqrt(sum((T_Vectors-EW)^2*T_Prop)*FPC) # SD with correction
SW<-sqrt(sum((T_Vectors-EW)^2*T_Prop))      # SD without correction
SWA
SW

EW2<-mean(DF$AvgLen)
EW2
T_WL2<-table(DF$AvgLen) 
T_Vectors2<-as.numeric(names(T_WL2)) 
PT2<-T_WL2/length(DF$AvgLen)                # Theoretical Probability
PT2
FPC<-(N-n)/(N-1)                            # Finite correction
SWA2<-sqrt(sum((T_Vectors2-EW2)^2*PT2)*FPC) # SD with correction
SW2<-sqrt(sum((T_Vectors2-EW2)^2*PT2))      # SD without correction
SW2
```

(m)  Based on your results, explain whether or not your simulation of $m = 10000$ students each taking a simple random sample of size $n = 81$ can be used to obtain an unbiased estimate of $\mu$. [3 pts]  

* *Based on my results, my stimulation of $m = 10000$ students each taking a simple random sample of size $n = 81$ can be used to obtain an unbiased estimate of $\mu$ because the result of `r EW2` is closed to `r EW`.*
 

(n) Create a density plot of the values in `AvgLen`.  Superimpose a normal distribution with a darkgreen line over the density plot using the parameters stored in `EW` and `SWA` for the mean and standard deviation respectively. Superimpose a second normal distribution with a lightblue line over the density plot using the parameters stored in `EW` and `SW` for the mean and standard deviation respectively. Does the darkgreen or lightblue line provide a better model for sampling without replacement?  [10 pts] 

```{r}
library(ggplot2)
DFA <- data.frame(AvgLen = DF$AvgLen)
## Using ggplot  
ggplot(DFA,aes(x=AvgLen)) +
   geom_density(binwidth=.15) +
   labs(x = "Word Lengths",y = "",
        title = "Density Plot of Average Word Length in AvgLen") +
   theme_bw() +
   stat_function(fun = dnorm, args = list(PT2,mean = EW2, sd = SWA2), colour = "#298A08") +
   stat_function(fun = dnorm, args = list(PT2,mean = EW2, sd = SW2), colour = "#85CAF5") 
```

* *The lightblue line provides a better model for sampling without replacement*

(o) Suppose you wanted to achieve sample means that tended to fall even closer to the population mean, would you increase the sample size or the number of samples? [2 pts]

* *I personally would increase the sample size. A larger sample size would decrease the value of standard deviation or less variation and increase the precision of the sample means to fall even closer to the population mean.*


(p) Use `set.seed = 145` to select a simple random sample of size ($n = 5$) from the words in the Gettysburg address and store the results in the object `SAMPLE`.  Write `R` code to determine the proportion of the words in `SAMPLE` that contain the letter `e`. [3 pts]

```{r}
set.seed(145)
n = 5 
SAMPLE <- sample(a$words, size=5, replace = FALSE)
SAMPLE
STR_E2 <- sum(stri_count_fixed(SAMPLE, 'e')>=1)
STR_E2
prop <- STR_E2/n
prop

```

* *The proportion of the words in `SAMPLE` that contain the letter `e` is `r prop`.*

(q) Construct 95% confidence intervals for $\pi$ the true proportion of words in the Gettysburg address that have at least one `e` using the Wald (asymptotic) and Agresti-Coull methods using the values obtained in (s).  What is the actual value for $\pi$?  Do either or both of the constructed confidence intervals contain $\pi$?  Interpret the constructed confidence intervals. [10 pts]   

```{r}
N<-length(GA$words)
prop
Wlsi <-prop-1.96*sqrt(prop*(1-prop)/5)
Wrsi <-prop+1.96*sqrt(prop*(1-prop)/5)
Wlsi
Wrsi

prop2 <- (STR_E2+2)/(n+4)
Alsi  <- prop2-1.96*sqrt(prop2*(1-prop2)/(n+4))
Arsi  <- prop2+1.96*sqrt(prop2*(1-prop2)/(n+4))
Alsi
Arsi

Pi <- sum(stri_count_fixed(a$words,"e")>=1)/N
Pi
```

*  *The Wald(asymptotic) confidence interval is `r Wlsi` to `r Wrsi`, and the Agresti-Coul methods confidence interval is `r Alsi` to `r Arsi`. The actual value for $\pi$ is `r Pi` which is contained in both constructed confidence intervals. For the Wald interval, there is a 95% probability that the actual value of $\pi$ would fall in between `r Wlsi` to `r Wrsi`. Similarly, there is a 95% probability that the actual value of $\pi$ would fall in between `r Alsi` to `r Arsi` for Agresti-Coul methods confidence interval.*

(r) Use `set.seed = 3` to select a simple random sample of size ($n = 5$) from the words in the Gettysburg address and store the results in the object `SAMPLE`.  Write `R` code to determine the proportion of the words in `SAMPLE` that contain the letter `e`.   Construct 95% confidence intervals for $\pi$ the true proportion of words in the Gettysburg address that have at least one `e` using the Wald (asymptotic) and Agresti-Coull methods.  Does the interpretation of the constructed confidence intervals change? [10 pts] 

```{r}
set.seed(3)
SAMPLE <- sample(a$words, size=5, replace = FALSE)
SAMPLE
STR_E3 <- sum(stri_count_fixed(SAMPLE, 'e')>=1)
STR_E3
prop3 <- STR_E3/n
prop3
```
*  *The proportion of the words in `SAMPLE` that contain the letter `e` is `r prop3`.*


```{r}
N<-length(GA$words)
Wlsi2 <-prop3-1.96*sqrt(prop3*(1-prop3)/5)
Wrsi2 <-prop3+1.96*sqrt(prop3*(1-prop3)/5)
Wlsi2
Wrsi2

prop4 <- (STR_E3+2)/(n+4)
Alsi2  <- prop4-1.96*sqrt(prop4*(1-prop4)/(n+4))
Arsi2  <- prop4+1.96*sqrt(prop4*(1-prop4)/(n+4))
Alsi2
Arsi2

Pi <- sum(stri_count_fixed(a$words,"e")>=1)/N
Pi
```
*  *The Wald(asymptotic) confidence interval is `r Wlsi2` to `r Wrsi2`, and the Agresti-Coul methods confidence interval is `r Alsi2` to `r Arsi2`. The actual value for $\pi$ is `r Pi` which is contained only in the constructed Agresti-Coul methods confidence interval. Again, for the Wald interval, there is a 95% probability that the actual value of $\pi$ would fall in between `r Wlsi2` to `r Wrsi2`.For Agresti-Coul methods confidence interval, there is a 95% probability that the actual value of $\pi$ would fall in between `r Alsi2` to `r Arsi2`.*


(s)  Suppose we are interested in testing whether the proportion of `the`s in a large work exceeds 10%.  If the true proportion of `the`s is 20% and we take a random sample of 100 words, what is the power of the test if the critical value used to reject the null hypothesis is 16 or more `the`s? [5 pts]

```{r}
s <- dbinom(16:100,100,0.2)
type2 <- sum(s)
power <- 1-type2
power
```

* *The power of the test if the critical value used to reject the null hypothesis is 16 or more `the` s is `r power`.*

